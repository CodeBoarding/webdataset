<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="description" content="None" />
      <link rel="shortcut icon" href="img/favicon.ico" />
    <title>webdataset</title>
    <link rel="stylesheet" href="css/theme.css" />
    <link rel="stylesheet" href="css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="assets/_mkdocstrings.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Home";
        var mkdocs_page_input_path = "index.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="." class="icon icon-home"> webdataset
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="" href="README.md">README</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="webdataset/">WebDataset</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="wids/">WIDS</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Examples</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="generate-text-dataset/">Dataset Generation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="tesseract-wds/">Tesseract wds</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="train-resnet50-wds/">Resnet 50 Training on (Fake)Imagenet with WebDataset</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="train-resnet50-wids/">Train resnet50 wids</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="train-resnet50-multiray-wds/">WebDataset + Distributed PyTorch Training</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="train-resnet50-multiray-wids/">WebIndexedDataset + Distributed PyTorch Training</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="train-ocr-errors-hf/">Fine Tuning LLM with Huggingface and WebDataset</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="mi-images/">Mini Imagenet Generation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="mi-prompts/">Mini Imagenet Generation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="wds-notes/">Wds notes</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="column-store/">Using WebDataset as a Column Store</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href=".">webdataset</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Home</li>
    <li class="wy-breadcrumbs-aside">
          <a href="http://github.com/webdataset/webdataset/edit/master/docs/index.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <p><a href="https://github.com/tmbdev/webdataset/actions?query=workflow%3ATest"><img alt="Test" src="https://github.com/tmbdev/webdataset/workflows/Test/badge.svg" /></a>
<a href="https://deepsource.io/gh/tmbdev/webdataset/?ref=repository-badge"><img alt="DeepSource" src="https://static.deepsource.io/deepsource-badge-light-mini.svg" /></a></p>
<pre><code class="language-python">%matplotlib inline
import matplotlib.pyplot as plt
import torch.utils.data
import torch.nn
from random import randrange
import os
os.environ[&quot;WDS_VERBOSE_CACHE&quot;] = &quot;1&quot;
os.environ[&quot;GOPEN_VERBOSE&quot;] = &quot;0&quot;
</code></pre>
<h1 id="the-webdataset-format">The WebDataset Format</h1>
<p>WebDataset format files are tar files, with two conventions:</p>
<ul>
<li>within each tar file, files that belong together and make up a training sample share the same basename when stripped of all filename extensions</li>
<li>the shards of a tar file are numbered like <code>something-000000.tar</code> to <code>something-012345.tar</code>, usually specified using brace notation <code>something-{000000..012345}.tar</code></li>
</ul>
<p>You can find a longer, more detailed specification of the WebDataset format in the <a href="https://docs.google.com/document/d/18OdLjruFNX74ILmgrdiCI9J1fQZuhzzRBCHV9URWto0/edit?usp=sharing">WebDataset Format Specification</a></p>
<p>WebDataset can read files from local disk or from any pipe, which allows it to access files using common cloud object stores. WebDataset can also read concatenated MsgPack and CBORs sources.</p>
<p>The WebDataset representation allows writing purely sequential I/O pipelines for large scale deep learning. This is important for achieving high I/O rates from local storage (3x-10x for local drives compared to random access) and for using object stores and cloud storage for training.</p>
<p>The WebDataset format represents images, movies, audio, etc. in their native file formats, making the creation of WebDataset format data as easy as just creating a tar archive. Because of the way data is aligned, WebDataset works well with block deduplication as well and aligns data on predictable boundaries.</p>
<p>Standard tools can be used for accessing and processing WebDataset-format files.</p>
<pre><code class="language-python">bucket = &quot;https://storage.googleapis.com/webdataset/testdata/&quot;
dataset = &quot;publaynet-train-{000000..000009}.tar&quot;

url = bucket + dataset
!curl -s {url} | tar tf - | sed 10q
</code></pre>
<pre><code>PMC4991227_00003.json
PMC4991227_00003.png
PMC4537884_00002.json
PMC4537884_00002.png
PMC4323233_00003.json
PMC4323233_00003.png
PMC5429906_00004.json
PMC5429906_00004.png
PMC5592712_00002.json
PMC5592712_00002.png
tar: stdout: write error
</code></pre>
<p>Note that in these <code>.tar</code> files, we have pairs of <code>.json</code> and <code>.png</code> files; each such pair makes up a training sample.</p>
<h1 id="webdataset-libraries">WebDataset Libraries</h1>
<p>There are several libraries supporting the WebDataset format:</p>
<ul>
<li><code>webdataset</code> for Python3 (includes the <code>wids</code> library), this repository</li>
<li><a href="https://github.com/webdataset/WebDataset.jl">Webdataset.jl</a> a Julia implementation</li>
<li><a href="https://github.com/webdataset/tarp">tarp</a>, a Golang implementation and command line tool</li>
<li>Ray Data sources and sinks</li>
</ul>
<p>The <code>webdataset</code> library can be used with PyTorch, Tensorflow, and Jax.</p>
<h1 id="the-webdataset-library">The <code>webdataset</code> Library</h1>
<p>The <code>webdataset</code> library is an implementation of PyTorch <code>IterableDataset</code> (or a mock implementation thereof if you aren't using PyTorch). It implements as form of stream processing. Some of its features are:</p>
<ul>
<li>large scale parallel data access through sharding</li>
<li>high performance disk I/O due to purely sequential reads</li>
<li>latency insensitive due to big fat pipes</li>
<li>no local storage required</li>
<li>instant startup for training jobs</li>
<li>only requires reading from file descriptors/network streams, no special APIs</li>
<li>its API encourages high performance I/O pipelines</li>
<li>scalable from tiny desktop datasets to petascale datasets</li>
<li>provides local caching if desired</li>
<li>requires no dataset metadata; any collection of shards can be read and used instantly</li>
</ul>
<p>The main limitations people run into are related to the fact that <code>IterableDataset</code> is less commonly used in PyTorch and some existing code may not support it as well, and that achieving an exactly balanced number of training samples across many compute nodes for a fixed epoch size is tricky; for multinode training, <code>webdataset</code> is usually used with shard resampling.</p>
<p>There are two interfaces, the concise "fluid" interface and a longer "pipeline" interface. We'll show examples using the fluid interface, which is usually what you want.</p>
<pre><code class="language-python">import webdataset as wds
pil_dataset = wds.WebDataset(url).shuffle(1000).decode(&quot;pil&quot;).to_tuple(&quot;png&quot;, &quot;json&quot;)
</code></pre>
<p>The resulting datasets are standard PyTorch <code>IterableDataset</code> instances.</p>
<pre><code class="language-python">isinstance(pil_dataset, torch.utils.data.IterableDataset)
</code></pre>
<pre><code>True
</code></pre>
<pre><code class="language-python">for image, json in pil_dataset:
    break
plt.imshow(image)
</code></pre>
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f73806db970&gt;
</code></pre>
<p><img alt="png" src="readme_files/readme_11_1.png" /></p>
<p>We can add onto the existing pipeline for augmentation and data preparation.</p>
<pre><code class="language-python">import torchvision.transforms as transforms
from PIL import Image

preproc = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    lambda x: 1-x,
])

def preprocess(sample):
    image, json = sample
    try:
        label = json[&quot;annotations&quot;][0][&quot;category_id&quot;]
    except:
        label = 0
    return preproc(image), label

dataset = pil_dataset.map(preprocess)

for image, label in dataset:
    break
plt.imshow(image.numpy().transpose(1, 2, 0))
</code></pre>
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f7375fc2230&gt;
</code></pre>
<p><img alt="png" src="readme_files/readme_13_1.png" /></p>
<p><code>WebDataset</code> is just an instance of a standard <code>IterableDataset</code>. It's a single-threaded way of iterating over a dataset. Since image decompression and data augmentation can be compute intensive, PyTorch usually uses the <code>DataLoader</code> class to parallelize data loading and preprocessing. <code>WebDataset</code> is fully compatible with the standard <code>DataLoader</code>.</p>
<p>Here are a number of notebooks showing how to use WebDataset for image classification and LLM training:</p>
<ul>
<li><a href="examples/out/train-resnet50-wds.ipynb">train-resnet50-wds</a> -- simple, single GPU training from Imagenet</li>
<li><a href="examples/out/train-resnet50-multiray-wds.ipynb">train-resnet50-multiray-wds</a> -- multinode training using webdataset</li>
<li><a href="examples/out/generate-text-dataset.ipynb">generate-text-dataset</a> -- initial dataset generation</li>
<li><a href="examples/out/tesseract-wds.ipynb">tesseract-wds</a> -- shard-to-shard transformations, here for OCR running over large datasets</li>
<li><a href="examples/out/train-ocr-errors-hf.ipynb">train-ocr-errors-hf</a> -- an example of LLM fine tuning using a dataset in webdataset format</li>
</ul>
<p>The <a href="examples/wds-notes.ipynb">wds-notes</a> notebook contains some additional documentation and information about the library.</p>
<h1 id="the-webdataset-pipeline-api">The <code>webdataset</code> Pipeline API</h1>
<p>The <code>wds.WebDataset</code> fluid interface is just a convenient shorthand for writing down pipelines. The underlying pipeline is an instance of the <code>wds.DataPipeline</code> class, and you can construct data pipelines explicitly, similar to the way you use <code>nn.Sequential</code> inside models.</p>
<pre><code class="language-python">dataset = wds.DataPipeline(
    wds.SimpleShardList(url),

    # at this point we have an iterator over all the shards
    wds.shuffle(100),

    # add wds.split_by_node here if you are using multiple nodes
    wds.split_by_worker,

    # at this point, we have an iterator over the shards assigned to each worker
    wds.tarfile_to_samples(),

    # this shuffles the samples in memory
    wds.shuffle(1000),

    # this decodes the images and json
    wds.decode(&quot;pil&quot;),
    wds.to_tuple(&quot;png&quot;, &quot;json&quot;),
    wds.map(preprocess),
    wds.shuffle(1000),
    wds.batched(16)
)

batch = next(iter(dataset))
batch[0].shape, batch[1].shape
</code></pre>
<pre><code>(torch.Size([16, 3, 224, 224]), (16,))
</code></pre>
<h1 id="the-wids-library-for-indexed-webdatasets">The <code>wids</code> Library for Indexed WebDatasets</h1>
<p>Installing the <code>webdataset</code> library installs a second library called <code>wids</code>. This library provides fully indexed/random access to the same datasets that <code>webdataset</code> accesses using iterators/streaming.</p>
<p>Like the <code>webdataset</code> library, <code>wids</code> is high scalable and provides efficient access to very large datasets. Being indexed, it is easily backwards compatible with existing data pipelines based on indexed dataset, including precise epochs for multinode training. The library comes with its own <code>ChunkedSampler</code> and <code>DistributedChunkedSampler</code> classes, which provided shuffling accross nodes while still preserving enough locality of reference for efficient training.</p>
<p>Internally, the library uses a <code>mmap</code>-based <code>tar</code> file reader implementation; this allows very fast access without precomputed indexes, and it also means that shard and the equivalet of "shuffle buffers" are shared in memory between workers on the same machine.</p>
<p>This additional power comes at some cost: the library requires a small metadata file that lists all the shards in a dataset and the number of samples contained in each, the library requires local storage for as many shards as there are I/O workers on a node, it uses shared memory and <code>mmap</code>, and the availability of indexing makes it easy to accidentally use inefficient access patterns.</p>
<p>Generally, the recommendation is to use <code>webdataset</code> for all data generation, data transformation, and training code, and to use <code>wids</code> only if you need fully random access to datasets (e.g., for browing or sparse sampling), need an indexed-based sampler, or are converting tricky legacy code.</p>
<pre><code class="language-python">import wids

train_url = &quot;https://storage.googleapis.com/webdataset/fake-imagenet/imagenet-train.json&quot;

dataset = wids.ShardListDataset(train_url)

sample = dataset[1900]

print(sample.keys())
print(sample[&quot;.txt&quot;])
plt.imshow(sample[&quot;.jpg&quot;])
</code></pre>
<pre><code>dict_keys(['.cls', '.jpg', '.txt', '__key__', '__dataset__', '__index__', '__shard__', '__shardindex__'])
a high quality color photograph of a dog


https://storage.googleapis.com/webdataset/fake-ima base: https://storage.googleapis.com/webdataset/fake-imagenet name: imagenet-train nfiles: 1282 nbytes: 31242280960 samples: 128200 cache: /tmp/_wids_cache





&lt;matplotlib.image.AxesImage at 0x7f7373669e70&gt;
</code></pre>
<p><img alt="png" src="readme_files/readme_19_3.png" /></p>
<p>There are several examples of how to use <code>wids</code> in the <a href="examples">examples</a> directory.</p>
<ul>
<li><a href="examples/out/train-resnet50-wids.ipynb">train-resnet50-wids</a> shows how to train a ResNet-50 model on ImageNet using <code>wids</code></li>
<li><a href="examples/out/train-resnet50-multiray-wids.ipynb">train-resnet50-multiray-wids</a> shows how to train a ResNet-50 model on ImageNet using multiple nodes</li>
</ul>
<p>Note that the APIs between <code>webdataset</code> and <code>wids</code> are not fully consistent:</p>
<ul>
<li><code>wids</code> keeps the extension's "." in the keys, while <code>webdataset</code> removes it (".txt" vs "txt")</li>
<li><code>wids</code> doesn't have a fully fluid interface, and <code>add_transformation</code> just adds to a list of transformations</li>
<li><code>webdataset</code> currently can't read the <code>wids</code> JSON specifications</li>
</ul>
<h1 id="installation-and-documentation">Installation and Documentation</h1>
<pre><code>$ pip install webdataset
</code></pre>
<p>For the Github version:</p>
<pre><code>$ pip install git+https://github.com/tmbdev/webdataset.git
</code></pre>
<p>Here are some videos talking about WebDataset and large scale deep learning:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=kNuA2wflygM">Introduction to Large Scale Deep Learning</a></li>
<li><a href="https://www.youtube.com/watch?v=mTv_ePYeBhs">Loading Training Data with WebDataset</a></li>
<li><a href="https://www.youtube.com/watch?v=v_PacO-3OGQ">Creating Datasets in WebDataset Format</a></li>
<li><a href="https://www.youtube.com/watch?v=kIv8zDpRUec">Tools for Working with Large Datasets</a></li>
</ul>
<h1 id="dependencies">Dependencies</h1>
<p>The WebDataset library only requires PyTorch, NumPy, and a small library called <code>braceexpand</code>.</p>
<p>WebDataset loads a few additional libraries dynamically only when they are actually needed and only in the decoder:</p>
<ul>
<li>PIL/Pillow for image decoding</li>
<li><code>torchvision</code>, <code>torchvideo</code>, <code>torchaudio</code> for image/video/audio decoding</li>
<li><code>msgpack</code> for MessagePack decoding</li>
<li>the <code>curl</code> command line tool for accessing HTTP servers</li>
<li>the Google/Amazon/Azure command line tools for accessing cloud storage buckets</li>
</ul>
<p>Loading of one of these libraries is triggered by configuring a decoder that attempts to decode content in the given format and encountering a file in that format during decoding. (Eventually, the torch... dependencies will be refactored into those libraries.)</p>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="http://github.com/webdataset/webdataset" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
    
  </span>
</div>
    <script src="js/jquery-3.6.0.min.js"></script>
    <script>var base_url = ".";</script>
    <script src="js/theme_extra.js"></script>
    <script src="js/theme.js"></script>
      <script src="search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>

<!--
MkDocs version : 1.6.1
Build Date UTC : 2024-09-21 01:30:56.974169+00:00
-->
