<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>Dataset Generation - webdataset</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../../../assets/_mkdocstrings.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Dataset Generation";
        var mkdocs_page_input_path = "examples/webdataset/generate-text-dataset.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> webdataset
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../..">README</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../webdataset/">WebDataset</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../wids/">WIDS</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../FAQ/">FAQ</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Examples</span></p>
              <ul class="current">
                  <li class="toctree-l1 current"><a class="reference internal current" >webdataset</a>
    <ul class="current">
                <li class="toctree-l2"><a class="reference internal" href="../">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../wds-notes/">Wds notes</a>
                </li>
                <li class="toctree-l2 current"><a class="reference internal current" href="#">Dataset Generation</a>
    <ul class="current">
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../tesseract-wds/">Tesseract wds</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../train-resnet50-wds/">Resnet 50 Training on (Fake)Imagenet with WebDataset</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../train-resnet50-multiray-wds/">WebDataset + Distributed PyTorch Training</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../train-ocr-errors-hf/">Fine Tuning LLM with Huggingface and WebDataset</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../mi-images/">Mini Imagenet Generation</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../mi-prompts/">Mini Imagenet Generation</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../column-store/">Using WebDataset as a Column Store</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >wids</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../wids/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../wids/train-resnet50-wids/">Train resnet50 wids</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../wids/train-resnet50-multiray-wids/">WebIndexedDataset + Distributed PyTorch Training</a>
                </li>
    </ul>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">webdataset</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">Examples</li>
          <li class="breadcrumb-item">webdataset</li>
      <li class="breadcrumb-item active">Dataset Generation</li>
    <li class="wy-breadcrumbs-aside">
          <a href="http://github.com/webdataset/webdataset/edit/master/docs/examples/webdataset/generate-text-dataset.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="dataset-generation">Dataset Generation</h1>
<p>This is a simple example of dataset generation using WebDataset <code>TarWriter</code>. Shard are uploaded to a server or to the cloud as they are generated.</p>
<p>Parallel dataset generation with Ray is illustrated at the very end.</p>
<p>This particular notebook generates short text samples using GPT-2. These can be used to generate OCR training data.</p>
<pre><code class="language-python"># package installs for colab

import sys

if &quot;google.colab&quot; in sys.modules:
    !pip install --quiet webdataset
    !pip install --quiet adapter-transformers
    !pip install --quiet sentencepiece
    !pip install --quiet datasets
</code></pre>
<pre><code class="language-python">import uuid
import webdataset as wds
import os

from transformers import GPT2LMHeadModel, GPT2Tokenizer
from transformers import pipeline
import textwrap
</code></pre>
<pre><code class="language-python"># Parameters
nsamples = 10
ntokens = 100
nshards = 3

</code></pre>
<pre><code class="language-python"># text generation with Huggingface and GPT2

tokenizer = GPT2Tokenizer.from_pretrained(&quot;gpt2&quot;, padding_side=&quot;left&quot;)
tokenizer.pad_token = tokenizer.eos_token
model = GPT2LMHeadModel.from_pretrained(&quot;gpt2&quot;)
generator = pipeline(&quot;text-generation&quot;, model=model, tokenizer=tokenizer)


def generate(n, prompt=&quot;&quot;):
    &quot;&quot;&quot;Generate n words of text, starting with prompt.&quot;&quot;&quot;
    global tokenizer, model, generator
    output = generator(
        prompt,
        max_length=n + len(tokenizer.encode(prompt)),
        do_sample=True,
        temperature=0.99,
        top_k=50,
        top_p=0.99,
        num_return_sequences=1,
        pad_token_id=tokenizer.eos_token_id,
    )[0]
    return output[&quot;generated_text&quot;]


text = generate(100).strip()
print()
print(textwrap.fill(text, 64))
</code></pre>
<pre><code class="language-python"># function generating an entire shard using TarWriter


def generate_shard(oname, nsamples=10000, ntokens=500, prefix=&quot;&quot;):
    &quot;&quot;&quot;Generate a shard of samples with text.

    Each sample has a &quot;__key__&quot; field and a &quot;txt.gz&quot; field.
    That is, the individual text files are compressed automatically on write.
    They will be automatically decompressed when read.
    &quot;&quot;&quot;
    with wds.TarWriter(oname) as output:
        for i in range(nsamples):
            text = generate(100).strip()
            key = uuid.uuid4().hex
            text = generate(ntokens)
            sample = {&quot;__key__&quot;: key, &quot;txt.gz&quot;: text}
            output.write(sample)
            if i % 10 == 0:
                print(f&quot;{i:6d} {prefix}:&quot;, repr(text)[:60])


generate_shard(&quot;temp.tar&quot;, nsamples=10, ntokens=10)
!ls -l temp.tar
!tar tf temp.tar | head -5
</code></pre>
<pre><code class="language-python"># We need a couple of simple functions to upload to the cloud.


def cloud_exists(oname):
    &quot;&quot;&quot;Check whether a file exists in the cloud.&quot;&quot;&quot;
    # return os.system(f&quot;gsutil stat gs://mybucket/500tokens/{oname}&quot;) == 0
    return True


def cloud_upload(oname):
    &quot;&quot;&quot;Upload a file to the cloud.&quot;&quot;&quot;
    # assert os.system(f&quot;gsutil cp {oname} gs://mybucket/500tokens/{oname}&quot;) == 0
    pass
</code></pre>
<pre><code class="language-python"># We can now generate a shard and upload it to the cloud.
# We skip the generation if the file already exists in the cloud.


def generate_and_upload(i):
    &quot;&quot;&quot;Generate a shard and upload it to the cloud.&quot;&quot;&quot;
    oname = f&quot;text-{i:06d}.tar&quot;
    if cloud_exists(oname):
        print(f&quot;{oname} already exists, skipping&quot;)
        return False
    generate_shard(oname, nsamples=nsamples, ntokens=ntokens, prefix=f&quot;{i:6d} {oname}&quot;)
    cloud_upload(oname)
    os.remove(oname)
    return True
</code></pre>
<pre><code class="language-python"># For sequential generation, use this

for i in range(nshards):
    generate_and_upload(i)
</code></pre>
<pre><code class="language-python">%%script true
# For parallel generation, use this

import ray

@ray.remote(num_cpus=1, num_gpus=1)
def ray_generate_and_upload(i):
    &quot;&quot;&quot;A Ray remote function that generates a shard and uploads it to the cloud.&quot;&quot;&quot;
    return generate_and_upload(i)

def generate_shards(nshards=10):
    &quot;&quot;&quot;Generate a number of shards and upload them to the cloud.

    Runs in parallel on a Ray cluster.
    &quot;&quot;&quot;
    ray.init(address='auto')  # Connect to the Ray cluster
    tasks = [ray_generate_and_upload.remote(i) for i in range(nshards)]
    ray.shutdown()
    return shard_names
</code></pre>
<pre><code class="language-python">
</code></pre>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../wds-notes/" class="btn btn-neutral float-left" title="Wds notes"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../tesseract-wds/" class="btn btn-neutral float-right" title="Tesseract wds">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="http://github.com/webdataset/webdataset" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../wds-notes/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../tesseract-wds/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../..";</script>
    <script src="../../../js/theme_extra.js"></script>
    <script src="../../../js/theme.js"></script>
      <script src="../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
